{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73426961",
   "metadata": {},
   "source": [
    "# Export the dataset\n",
    "\n",
    "This step preprocesses the data for modelling by:\n",
    "  - Median imputation for numerical variables\n",
    "  - Mode imputation and one-hot encoding categorical variables\n",
    "  - Aligning the train/test columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0734ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train_merged: (307511, 181)\n",
      "Loaded test_merged: (48744, 180)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "CLEAN_DIR = Path(\"../data/clean\")\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_merged = pd.read_csv(CLEAN_DIR / \"train_merged.csv\")\n",
    "test_merged  = pd.read_csv(CLEAN_DIR / \"test_merged.csv\")\n",
    "\n",
    "print(\"Loaded train_merged:\", train_merged.shape)\n",
    "print(\"Loaded test_merged:\", test_merged.shape)\n",
    "\n",
    "train_merged = train_merged.replace([np.inf, -np.inf], np.nan)\n",
    "test_merged  = test_merged.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def clip_extreme_values(df, max_abs=1e12):\n",
    "    num_cols_local = df.select_dtypes(include=[np.number]).columns\n",
    "    df[num_cols_local] = df[num_cols_local].clip(lower=-max_abs, upper=max_abs)\n",
    "    return df\n",
    "\n",
    "train_merged = clip_extreme_values(train_merged)\n",
    "test_merged  = clip_extreme_values(test_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa45e8c",
   "metadata": {},
   "source": [
    "### 1. Separate target and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461eb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"TARGET\"\n",
    "ID_COL = \"SK_ID_CURR\"\n",
    "\n",
    "y = train_merged[TARGET_COL]\n",
    "\n",
    "\n",
    "id_train = train_merged[ID_COL].values\n",
    "id_test  = test_merged[ID_COL].values\n",
    "\n",
    "\n",
    "X_train_raw = train_merged.drop(columns=[TARGET_COL])\n",
    "X_test_raw  = test_merged.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f676d1",
   "metadata": {},
   "source": [
    "### 2. Identify categorical vs numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b64fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical cols: 14\n",
      "Number of numeric cols: 165\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [c for c in X_train_raw.columns if c != ID_COL]\n",
    "\n",
    "cat_cols = X_train_raw[feature_cols].select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "num_cols = X_train_raw[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Number of categorical cols:\", len(cat_cols))\n",
    "print(\"Number of numeric cols:\", len(num_cols))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf7a0aa",
   "metadata": {},
   "source": [
    "### 3. Build the preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03bdd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e8165",
   "metadata": {},
   "source": [
    "### 4. Fit on train only, the transform both train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4095f9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed train shape: (307511, 301)\n",
      "Transformed test shape: (48744, 301)\n"
     ]
    }
   ],
   "source": [
    "X_train_arr = preprocessor.fit_transform(X_train_raw[feature_cols])\n",
    "X_test_arr  = preprocessor.transform(X_test_raw[feature_cols])\n",
    "\n",
    "print(\"Transformed train shape:\", X_train_arr.shape)\n",
    "print(\"Transformed test shape:\", X_test_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea893e",
   "metadata": {},
   "source": [
    "### 5. Build feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9edf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature count matches train array? True\n"
     ]
    }
   ],
   "source": [
    "num_feature_names = num_cols\n",
    "\n",
    "ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"encoder\"]\n",
    "ohe_feature_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "\n",
    "final_feature_names = num_feature_names + ohe_feature_names\n",
    "\n",
    "print(\"Feature count matches train array?\",\n",
    "      len(final_feature_names) == X_train_arr.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4884b4b",
   "metadata": {},
   "source": [
    "### 6. Wrap back into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6fc4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_model shape: (307511, 303)\n",
      "X_test_model shape: (48744, 302)\n",
      "Train NaN % rows w/ any NaN: 0.0\n",
      "Test NaN % rows w/ any NaN: 0.0\n"
     ]
    }
   ],
   "source": [
    "X_train_model = pd.DataFrame(X_train_arr, columns=final_feature_names, index=X_train_raw.index)\n",
    "X_train_model.insert(0, ID_COL, id_train)\n",
    "X_train_model[TARGET_COL] = y.values\n",
    "\n",
    "X_test_model = pd.DataFrame(X_test_arr, columns=final_feature_names, index=X_test_raw.index)\n",
    "X_test_model.insert(0, ID_COL, id_test)\n",
    "\n",
    "print(\"X_train_model shape:\", X_train_model.shape)\n",
    "print(\"X_test_model shape:\", X_test_model.shape)\n",
    "\n",
    "print(\"Train NaN % rows w/ any NaN:\", np.mean(X_train_model.isna().any(axis=1)))\n",
    "print(\"Test NaN % rows w/ any NaN:\", np.mean(X_test_model.isna().any(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c570d",
   "metadata": {},
   "source": [
    "## 7. Export final modeling datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdbaf685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../data/clean/model_train.csv\n",
      "Saved ../data/clean/model_test.csv\n"
     ]
    }
   ],
   "source": [
    "model_train_path = CLEAN_DIR / \"model_train.csv\"\n",
    "model_test_path  = CLEAN_DIR / \"model_test.csv\"\n",
    "\n",
    "X_train_model.to_csv(model_train_path, index=False)\n",
    "X_test_model.to_csv(model_test_path, index=False)\n",
    "\n",
    "print(f\"Saved {model_train_path}\")\n",
    "print(f\"Saved {model_test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3839d7-8046-444f-be5c-5b7b97a30610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project_venv)",
   "language": "python",
   "name": "project_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
