{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e98d1e4-86ab-47d4-9118-b5f195eedd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the Home Credit Dataset. The focus here is on the application_train.csv, since it\n",
    "# contains the information used to train the model and defines if a loan was defaulted or not.\n",
    "\n",
    "# 1. Import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a1fc7e-2e46-439d-807f-1526e356444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Data Paths and define Target\n",
    "DATA_PATH = Path(\"../data/raw/application_train.csv\")\n",
    "OUT_DIR = Path(\"../data/clean/\")\n",
    "TARGET = \"TARGET\"\n",
    "UNIQUE_KEY = \"SK_ID_CURR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e261b10c-c102-4d86-ab3c-7222d9cbfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "orig_shape = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a6520a-9f7c-49d1-a15a-af3e20abe455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Helper functions to group very rare categories.\n",
    "def safe_div(a, b):\n",
    "    return np.where((b==0) | (pd.isna(b)), np.nan, a / b)\n",
    "\n",
    "def reduce_rare(series, min_ratio=0.005):\n",
    "    \"\"\"Group very rare categories (<0.5%) into 'Other'.\"\"\"\n",
    "    vc = series.value_counts(normalize=True, dropna=False)\n",
    "    keep = set(vc[vc >= min_ratio].index)\n",
    "    return series.where(series.isin(keep), other=\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49b5d2da-24ec-4bac-946a-baf9d2dd2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "missing = df.isna().sum().sort_values(ascending=False).to_frame(\"n_missing\")\n",
    "missing[\"pct_missing\"] = (missing[\"n_missing\"]/len(df)*100).round(2)\n",
    "missing.to_csv(OUT_DIR/\"missing_summary.csv\")\n",
    "\n",
    "with open(OUT_DIR/\"quick_info.txt\",\"w\") as f:\n",
    "    f.write(f\"Rows x Cols: {df.shape}\\n\")\n",
    "    if TARGET in df:\n",
    "        f.write(df[TARGET].value_counts().to_string()+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d9cbea-b503-4b98-8923-016035179714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Data Quality Checks\n",
    "dq = {}\n",
    "dq[\"unique_ids\"] = (df[UNIQUE_KEY].is_unique if UNIQUE_KEY in df.columns else \"UNAVAILABLE\")\n",
    "dq[\"duplicate_rows\"] = int(df.duplicated().sum())\n",
    "dq[\"constant_columns\"] = [c for c in df.columns if df[c].nunique(dropna=False) == 1]\n",
    "dq[\"high_missing_over_60pct\"] = missing.index[missing[\"pct_missing\"]>=60].tolist()\n",
    "\n",
    "if \"DAYS_EMPLOYED\" in df:\n",
    "    dq[\"DAYS_EMPLOYED_365243_count\"] = int((df[\"DAYS_EMPLOYED\"]==365243).sum())\n",
    "if \"CODE_GENDER\" in df:\n",
    "    dq[\"CODE_GENDER_counts\"] = df[\"CODE_GENDER\"].value_counts(dropna=False).to_dict()\n",
    "\n",
    "pd.Series(dq, dtype=\"object\").to_json(OUT_DIR/\"data_quality_checks.json\", indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7117fbcd-dc52-41f4-9da4-a5c84e50a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "dfc = df.copy() # Create a copy of the datafrane\n",
    "\n",
    "# 1) sentinel in DAYS_EMPLOYED\n",
    "if \"DAYS_EMPLOYED\" in dfc:\n",
    "    dfc.loc[dfc[\"DAYS_EMPLOYED\"] == 365243, \"DAYS_EMPLOYED\"] = np.nan\n",
    "\n",
    "# 2) check for rare/invalid gender label\n",
    "if \"CODE_GENDER\" in dfc:\n",
    "    dfc.loc[dfc[\"CODE_GENDER\"] == \"XNA\", \"CODE_GENDER\"] = np.nan\n",
    "\n",
    "# 3) check for impossible counts -> NaN\n",
    "for c in [\"CNT_CHILDREN\", \"CNT_FAM_MEMBERS\"]:\n",
    "    if c in dfc:\n",
    "        dfc.loc[dfc[c] < 0, c] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7911ad14-3f62-4e69-8a52-8ffd92804a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "fe = dfc.copy()\n",
    "\n",
    "# Make sure the years are human-readable\n",
    "if \"DAYS_BIRTH\" in fe:\n",
    "    fe[\"AGE_YEARS\"] = (-fe[\"DAYS_BIRTH\"]/365.25).round(2)\n",
    "if \"DAYS_EMPLOYED\" in fe:\n",
    "    fe[\"EMPLOYED_YEARS\"] = (-fe[\"DAYS_EMPLOYED\"]/365.25).round(2)\n",
    "\n",
    "# ratios\n",
    "if {\"AMT_CREDIT\",\"AMT_INCOME_TOTAL\"}.issubset(fe.columns):\n",
    "    fe[\"CREDIT_TO_INCOME\"] = safe_div(fe[\"AMT_CREDIT\"], fe[\"AMT_INCOME_TOTAL\"])\n",
    "if {\"AMT_ANNUITY\",\"AMT_INCOME_TOTAL\"}.issubset(fe.columns):\n",
    "    fe[\"ANNUITY_TO_INCOME\"] = safe_div(fe[\"AMT_ANNUITY\"], fe[\"AMT_INCOME_TOTAL\"])\n",
    "if {\"AMT_ANNUITY\",\"AMT_CREDIT\"}.issubset(fe.columns):\n",
    "    fe[\"PAYMENT_RATE\"] = safe_div(fe[\"AMT_ANNUITY\"], fe[\"AMT_CREDIT\"])\n",
    "if {\"AMT_GOODS_PRICE\",\"AMT_CREDIT\"}.issubset(fe.columns):\n",
    "    fe[\"GOODS_CREDIT_RATIO\"] = safe_div(fe[\"AMT_GOODS_PRICE\"], fe[\"AMT_CREDIT\"])\n",
    "\n",
    "# household\n",
    "if {\"CNT_CHILDREN\",\"CNT_FAM_MEMBERS\"}.issubset(fe.columns):\n",
    "    fe[\"CHILDREN_RATIO\"] = safe_div(fe[\"CNT_CHILDREN\"], fe[\"CNT_FAM_MEMBERS\"])\n",
    "if {\"AMT_INCOME_TOTAL\",\"CNT_FAM_MEMBERS\"}.issubset(fe.columns):\n",
    "    fe[\"INCOME_PER_PERSON\"] = safe_div(fe[\"AMT_INCOME_TOTAL\"], fe[\"CNT_FAM_MEMBERS\"])\n",
    "\n",
    "# docs aggregate\n",
    "doc_cols = [c for c in fe.columns if c.startswith(\"FLAG_DOCUMENT\")]\n",
    "if doc_cols:\n",
    "    fe[\"N_DOCS_PROVIDED\"] = fe[doc_cols].sum(axis=1)\n",
    "\n",
    "# EXT_SOURCE aggregates\n",
    "ext_cols = [c for c in fe.columns if c.startswith(\"EXT_SOURCE\")]\n",
    "if ext_cols:\n",
    "    fe[\"EXT_SOURCES_MEAN\"] = fe[ext_cols].mean(axis=1)\n",
    "    fe[\"EXT_SOURCES_MIN\"]  = fe[ext_cols].min(axis=1)\n",
    "    fe[\"EXT_SOURCES_MAX\"]  = fe[ext_cols].max(axis=1)\n",
    "\n",
    "# log transforms for skewed amounts\n",
    "for col in [\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"AMT_ANNUITY\",\"AMT_GOODS_PRICE\"]:\n",
    "    if col in fe:\n",
    "        fe[f\"LOG1P_{col}\"] = np.log1p(fe[col].clip(lower=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b87052-8830-4d2d-a793-786150c69fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation and Encoding\n",
    "num_cols = fe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = fe.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# numeric: median; categorical: \"Missing\"\n",
    "fe[num_cols] = fe[num_cols].fillna(fe[num_cols].median())\n",
    "fe[cat_cols] = fe[cat_cols].fillna(\"Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c67e981a-adc9-49a8-9924-ffba6eb38629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the rare categories\n",
    "for c in cat_cols:\n",
    "    fe[c] = reduce_rare(fe[c], min_ratio=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b1d4ecc-7eec-49de-98a9-db1ccb94258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with 80%+ missin\n",
    "cols_to_consider_drop = set(missing.index[missing[\"pct_missing\"]>=80].tolist())\n",
    "cols_to_drop = [c for c in fe.columns if c in cols_to_consider_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a400879-28d5-4b71-b3ff-59602378b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = min(20000, len(fe))\n",
    "fe_sample = fe.iloc[:n_sample].copy()\n",
    "model_matrix_sample = pd.get_dummies(fe_sample, columns=cat_cols, dummy_na=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9b85276-185e-4e4e-9944-02b85c74f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for correlation\n",
    "if TARGET in fe:\n",
    "    numeric_cols = fe.select_dtypes(include=[np.number]).columns\n",
    "    corr = fe[numeric_cols].corrwith(df[TARGET]).sort_values(ascending=False)\n",
    "    corr.to_frame(\"corr_with_TARGET\").to_csv(OUT_DIR/\"feature_target_correlations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d2fa0bf-3399-458c-8d1c-876f155d3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.head(10000).to_csv(OUT_DIR/\"application_train_engineered_sample.csv\", index=False) \n",
    "model_matrix_sample.to_csv(OUT_DIR/\"application_train_model_matrix_sample.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "445b0df7-9944-4045-ad82-7660ebee3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Plots for AGE Years and Employed Years\n",
    "plt.figure()\n",
    "df[TARGET].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"TARGET distribution (0=repaid, 1=default)\")\n",
    "plt.xlabel(\"TARGET\"); plt.ylabel(\"Count\")\n",
    "plt.tight_layout(); plt.savefig(OUT_DIR/\"target_distribution.png\"); plt.close()\n",
    "\n",
    "if \"AGE_YEARS\" in fe:\n",
    "    plt.figure()\n",
    "    fe[\"AGE_YEARS\"].dropna().plot(kind=\"hist\", bins=40)\n",
    "    plt.title(\"Distribution of AGE_YEARS\"); plt.xlabel(\"Age (years)\"); plt.ylabel(\"Count\")\n",
    "    plt.tight_layout(); plt.savefig(OUT_DIR/\"hist_age_years.png\"); plt.close()\n",
    "\n",
    "if \"EMPLOYED_YEARS\" in fe:\n",
    "    plt.figure()\n",
    "    fe[\"EMPLOYED_YEARS\"].dropna().clip(upper=60).plot(kind=\"hist\", bins=40)\n",
    "    plt.title(\"Distribution of EMPLOYED_YEARS (clipped at 60)\"); plt.xlabel(\"Years\"); plt.ylabel(\"Count\")\n",
    "    plt.tight_layout(); plt.savefig(OUT_DIR/\"hist_employed_years.png\"); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9db5ced-2ae6-4e2d-937f-04ed9f91c89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. See ./outputs for CSVs & PNGs.\n"
     ]
    }
   ],
   "source": [
    "summary = {\n",
    "    \"raw_shape\": df.shape,\n",
    "    \"engineered_shape\": fe.shape,\n",
    "    \"model_matrix_sample_shape\": model_matrix_sample.shape,\n",
    "    \"dropped_candidates(>=80%missing)_count\": len(cols_to_drop),\n",
    "}\n",
    "pd.Series(summary, dtype=\"object\").to_csv(OUT_DIR/\"summary_stats.csv\")\n",
    "\n",
    "print(\"Done. See ./outputs for CSVs & PNGs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4b021-05b1-4e05-a7c1-c757e5bb6dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
