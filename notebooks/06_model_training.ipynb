{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5daab015",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "In this step, we load the model-ready dataset and train a model including class weighting due to class imbalances. The model will be evaluated using an ROC-AUC on the validation split since this is a binary classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86150762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (307511, 303)\n",
      "Test shape: (48744, 302)\n",
      "Default rate in train (TARGET==1): 0.08072881945686496\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set Path variables for data importation\n",
    "CLEAN_DIR = Path(\"../data/clean\")\n",
    "\n",
    "# Set Path variables for exporting prediction data\n",
    "OUT_VAL_PATH = CLEAN_DIR / \"oof_val_preds.csv\"\n",
    "OUT_TEST_PATH = CLEAN_DIR / \"test_predictions.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(CLEAN_DIR / \"model_train.csv\")\n",
    "test_df  = pd.read_csv(CLEAN_DIR / \"model_test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"Default rate in train (TARGET==1):\", train_df[\"TARGET\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7ce84",
   "metadata": {},
   "source": [
    "### A. Prepare the feature labels and IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b58acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (307511, 301)\n",
      "X_test_final shape: (48744, 301)\n"
     ]
    }
   ],
   "source": [
    "TARGET_COL = \"TARGET\"\n",
    "ID_COL = \"SK_ID_CURR\"\n",
    "\n",
    "# target\n",
    "y = train_df[TARGET_COL].astype(int).values\n",
    "\n",
    "# copy feature frames\n",
    "X = train_df.drop(columns=[TARGET_COL]).copy()\n",
    "X_test_final = test_df.copy()\n",
    "\n",
    "# save ids separately\n",
    "id_train = X[ID_COL].values\n",
    "id_test  = X_test_final[ID_COL].values\n",
    "\n",
    "# remove ID column from model features\n",
    "X = X.drop(columns=[ID_COL])\n",
    "X_test_final = X_test_final.drop(columns=[ID_COL])\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"X_test_final shape:\", X_test_final.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26499876",
   "metadata": {},
   "source": [
    "### B. Use a stratified approach to split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c580c106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split shape: (246008, 301)\n",
      "Valid split shape: (61503, 301)\n",
      "Validation default rate: 0.08072776937710356\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_val, y_tr, y_val, id_tr, id_val = train_test_split(\n",
    "    X, y, id_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train split shape:\", X_tr.shape)\n",
    "print(\"Valid split shape:\", X_val.shape)\n",
    "print(\"Validation default rate:\", y_val.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935bfee",
   "metadata": {},
   "source": [
    "### B. Train a LightGBM Model\n",
    "LightGBM is an ensemble learning framework that employs gradient boosting method. It sequentially adds weak learners creating a strong learner. It works well with large datasets as this one, and is effective in memory usage. It is prefered because it leads to:\n",
    "- Faster training speed and higher efficiency.\n",
    "\n",
    "- Lower memory usage.\n",
    "\n",
    "- Better accuracy.\n",
    "\n",
    "- Supports of parallel, distributed, and GPU learning.\n",
    "\n",
    "- Capable of handling large-scale data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0d55eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight = 11.38710976837865\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_pos_weight =\u001b[39m\u001b[38;5;124m\"\u001b[39m, pos_weight)\n\u001b[1;32m      8\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     20\u001b[0m }\n\u001b[0;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     23\u001b[0m     params,\n\u001b[1;32m     24\u001b[0m     lgb_train,\n\u001b[1;32m     25\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[lgb_train, lgb_valid],\n\u001b[1;32m     26\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     27\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m,\n\u001b[1;32m     28\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     29\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest iteration:\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mbest_iteration)\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# Create a wrap data for LightGBM\n",
    "lgb_train = lgb.Dataset(X_tr, label=y_tr)\n",
    "lgb_valid = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "pos_weight = (y_tr==0).sum() / max((y_tr==1).sum(), 1)\n",
    "print(\"scale_pos_weight =\", pos_weight)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"scale_pos_weight\": pos_weight,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    valid_names=[\"train\",\"valid\"],\n",
    "    num_boost_round=5000,\n",
    "    early_stopping_rounds=200,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "print(\"Best iteration:\", model.best_iteration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7abf7",
   "metadata": {},
   "source": [
    "## 4. Validation performance (ROC-AUC + ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a844379",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_proba = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "val_auc = roc_auc_score(y_val, val_pred_proba)\n",
    "print(\"Validation ROC-AUC:\", val_auc)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, val_pred_proba)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1],\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"ROC Curve (AUC={val_auc:.4f})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be30344a",
   "metadata": {},
   "source": [
    "## 5. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d27a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importance(importance_type=\"gain\")\n",
    "feat_imp = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"importance_gain\": importances\n",
    "    })\n",
    "    .sort_values(\"importance_gain\", ascending=False)\n",
    ")\n",
    "\n",
    "print(feat_imp.head(20))\n",
    "\n",
    "plt.figure(figsize=(6,8))\n",
    "feat_imp.head(25).sort_values(\"importance_gain\").plot(\n",
    "    kind=\"barh\",\n",
    "    x=\"feature\",\n",
    "    y=\"importance_gain\"\n",
    ")\n",
    "plt.title(\"Top 25 Feature Importances (gain)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bc6dfa",
   "metadata": {},
   "source": [
    "## 6. Save validation predictions for analysis / threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_DIR = Path(\"data/clean\")\n",
    "OUT_VAL_PATH = CLEAN_DIR / \"oof_val_preds.csv\"\n",
    "\n",
    "val_results = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": id_val,\n",
    "    \"TARGET\": y_val,\n",
    "    \"PRED_PROB\": val_pred_proba\n",
    "})\n",
    "val_results.to_csv(OUT_VAL_PATH, index=False)\n",
    "print(\"Wrote validation preds to:\", OUT_VAL_PATH)\n",
    "\n",
    "val_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff28258",
   "metadata": {},
   "source": [
    "## 7. Final model on FULL data + test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951d9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train final model using all rows\n",
    "full_lgb_train = lgb.Dataset(X, label=y)\n",
    "\n",
    "final_model = lgb.train(\n",
    "    {**params, \"verbose\": -1},\n",
    "    full_lgb_train,\n",
    "    num_boost_round=model.best_iteration  # reuse best iteration from earlier fit\n",
    ")\n",
    "\n",
    "# predict on test\n",
    "test_pred_proba = final_model.predict(X_test_final)\n",
    "\n",
    "submission_like = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": id_test,\n",
    "    \"PRED_PROB\": test_pred_proba\n",
    "})\n",
    "\n",
    "OUT_TEST_PATH = CLEAN_DIR / \"test_predictions.csv\"\n",
    "submission_like.to_csv(OUT_TEST_PATH, index=False)\n",
    "\n",
    "print(\"Wrote test predictions to:\", OUT_TEST_PATH)\n",
    "submission_like.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project_venv)",
   "language": "python",
   "name": "project_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
